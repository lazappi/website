[
    {
        "task_id": "label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_id' should be defined\n  Task id: label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_name' should be defined\n  Task id: label_projection\n  Field: task_name\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_summary' should be defined\n  Task id: label_projection\n  Field: task_summary\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Task info", 
        "name": "Pct 'task_description' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing([task_info], field)", 
        "message": "Task metadata field 'task_description' should be defined\n  Task id: label_projection\n  Field: task_description\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Method info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'task_id' should be defined\n  Task id: label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Method info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'commit_sha' should be defined\n  Task id: label_projection\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Method info", 
        "name": "Pct 'method_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_id' should be defined\n  Task id: label_projection\n  Field: method_id\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Method info", 
        "name": "Pct 'method_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_name' should be defined\n  Task id: label_projection\n  Field: method_name\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Method info", 
        "name": "Pct 'method_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'method_summary' should be defined\n  Task id: label_projection\n  Field: method_summary\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Method info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'paper_reference' should be defined\n  Task id: label_projection\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Method info", 
        "name": "Pct 'is_baseline' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(method_info, field)", 
        "message": "Method metadata field 'is_baseline' should be defined\n  Task id: label_projection\n  Field: is_baseline\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Metric info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'task_id' should be defined\n  Task id: label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Metric info", 
        "name": "Pct 'commit_sha' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'commit_sha' should be defined\n  Task id: label_projection\n  Field: commit_sha\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Metric info", 
        "name": "Pct 'metric_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_id' should be defined\n  Task id: label_projection\n  Field: metric_id\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Metric info", 
        "name": "Pct 'metric_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_name' should be defined\n  Task id: label_projection\n  Field: metric_name\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Metric info", 
        "name": "Pct 'metric_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'metric_summary' should be defined\n  Task id: label_projection\n  Field: metric_summary\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Metric info", 
        "name": "Pct 'paper_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'paper_reference' should be defined\n  Task id: label_projection\n  Field: paper_reference\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Metric info", 
        "name": "Pct 'maximize' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(metric_info, field)", 
        "message": "Metric metadata field 'maximize' should be defined\n  Task id: label_projection\n  Field: maximize\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'task_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'task_id' should be defined\n  Task id: label_projection\n  Field: task_id\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_id' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_id' should be defined\n  Task id: label_projection\n  Field: dataset_id\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_name' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_name' should be defined\n  Task id: label_projection\n  Field: dataset_name\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'dataset_summary' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'dataset_summary' should be defined\n  Task id: label_projection\n  Field: dataset_summary\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'data_reference' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_reference' should be defined\n  Task id: label_projection\n  Field: data_reference\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Dataset info", 
        "name": "Pct 'data_url' missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "percent_missing(dataset_info, field)", 
        "message": "Dataset metadata field 'data_url' should be defined\n  Task id: label_projection\n  Field: data_url\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw data", 
        "name": "Number of results", 
        "value": 88, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "len(results) == len(method_info) * len(metric_info) * len(dataset_info)", 
        "message": "Number of results should be equal to #methods × #metrics × #datasets.\n  Task id: label_projection\n  Number of results: 88\n  Number of methods: 8\n  Number of metrics: 4\n  Number of datasets: 11\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Metric 'accuracy' %missing", 
        "value": 0.10227272727272729, 
        "severity": 1, 
        "severity_value": 1.022727272727273, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  Metric id: accuracy\n  Percentage missing: 10%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Metric 'f1_weighted' %missing", 
        "value": 0.10227272727272729, 
        "severity": 1, 
        "severity_value": 1.022727272727273, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  Metric id: f1_weighted\n  Percentage missing: 10%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Metric 'f1_macro' %missing", 
        "value": 0.10227272727272729, 
        "severity": 1, 
        "severity_value": 1.022727272727273, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  Metric id: f1_macro\n  Percentage missing: 10%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Metric 'f1_micro' %missing", 
        "value": 0.10227272727272729, 
        "severity": 1, 
        "severity_value": 1.022727272727273, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  Metric id: f1_micro\n  Percentage missing: 10%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'true_labels' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: true_labels\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'majority_vote' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: majority_vote\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'random_labels' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: random_labels\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'knn' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: knn\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'logistic_regression' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: logistic_regression\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'mlp' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: mlp\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'scanvi_scarches' %missing", 
        "value": 0.4545454545454546, 
        "severity": 3, 
        "severity_value": 4.545454545454546, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: scanvi_scarches\n  Percentage missing: 45%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Method 'xgboost' %missing", 
        "value": 0.36363636363636365, 
        "severity": 3, 
        "severity_value": 3.6363636363636362, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  method id: xgboost\n  Percentage missing: 36%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/mouse_pancreas_atlas' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: cellxgene_census/mouse_pancreas_atlas\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/hypomap' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: cellxgene_census/hypomap\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/dkd' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: cellxgene_census/dkd\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/hcla' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: cellxgene_census/hcla\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/gtex_v9' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: cellxgene_census/gtex_v9\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_v1/immune_cells' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: openproblems_v1/immune_cells\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_v1/cengen' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: openproblems_v1/cengen\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/immune_cell_atlas' %missing", 
        "value": 0.125, 
        "severity": 1, 
        "severity_value": 1.25, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: cellxgene_census/immune_cell_atlas\n  Percentage missing: 12%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_v1/zebrafish' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: openproblems_v1/zebrafish\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'cellxgene_census/tabula_sapiens' %missing", 
        "value": 0.25, 
        "severity": 2, 
        "severity_value": 2.5, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: cellxgene_census/tabula_sapiens\n  Percentage missing: 25%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Raw results", 
        "name": "Dataset 'openproblems_v1/pancreas' %missing", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": 0.0, 
        "code": "pct_missing <= .1", 
        "message": "Percentage of missing results should be less than 10%.\n  Task id: label_projection\n  dataset id: openproblems_v1/pancreas\n  Percentage missing: 0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels accuracy", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: accuracy\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels accuracy", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: accuracy\n  Best score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote accuracy", 
        "value": 0.7133, 
        "severity": 0, 
        "severity_value": 0.35665, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: accuracy\n  Best score: 0.7133%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels accuracy", 
        "value": 0.058, 
        "severity": 0, 
        "severity_value": 0.029, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: accuracy\n  Best score: 0.058%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn accuracy", 
        "value": 0.2192, 
        "severity": 0, 
        "severity_value": -0.2192, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: accuracy\n  Worst score: 0.2192%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score knn accuracy", 
        "value": 0.9936, 
        "severity": 0, 
        "severity_value": 0.4968, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: accuracy\n  Best score: 0.9936%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression accuracy", 
        "value": 0.1012, 
        "severity": 0, 
        "severity_value": -0.1012, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: accuracy\n  Worst score: 0.1012%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression accuracy", 
        "value": 0.9936, 
        "severity": 0, 
        "severity_value": 0.4968, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: accuracy\n  Best score: 0.9936%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp accuracy", 
        "value": 0.2012, 
        "severity": 0, 
        "severity_value": -0.2012, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: accuracy\n  Worst score: 0.2012%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp accuracy", 
        "value": 0.9957, 
        "severity": 0, 
        "severity_value": 0.49785, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: accuracy\n  Best score: 0.9957%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches accuracy", 
        "value": 0.9497, 
        "severity": 0, 
        "severity_value": 0.47485, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: accuracy\n  Best score: 0.9497%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost accuracy", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: accuracy\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost accuracy", 
        "value": 0.9438, 
        "severity": 0, 
        "severity_value": 0.4719, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: accuracy\n  Best score: 0.9438%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels f1_weighted", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: f1_weighted\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels f1_weighted", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: f1_weighted\n  Best score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote f1_weighted", 
        "value": 0.5185, 
        "severity": 0, 
        "severity_value": 0.25925, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: f1_weighted\n  Best score: 0.5185%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels f1_weighted", 
        "value": 0.0952, 
        "severity": 0, 
        "severity_value": 0.0476, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: f1_weighted\n  Best score: 0.0952%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn f1_weighted", 
        "value": 0.2672, 
        "severity": 0, 
        "severity_value": -0.2672, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: f1_weighted\n  Worst score: 0.2672%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score knn f1_weighted", 
        "value": 0.9928, 
        "severity": 0, 
        "severity_value": 0.4964, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: f1_weighted\n  Best score: 0.9928%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression f1_weighted", 
        "value": 0.1264, 
        "severity": 0, 
        "severity_value": -0.1264, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: f1_weighted\n  Worst score: 0.1264%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression f1_weighted", 
        "value": 0.9928, 
        "severity": 0, 
        "severity_value": 0.4964, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: f1_weighted\n  Best score: 0.9928%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp f1_weighted", 
        "value": 0.233, 
        "severity": 0, 
        "severity_value": -0.233, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: f1_weighted\n  Worst score: 0.233%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp f1_weighted", 
        "value": 0.9954, 
        "severity": 0, 
        "severity_value": 0.4977, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: f1_weighted\n  Best score: 0.9954%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches f1_weighted", 
        "value": 0.9422, 
        "severity": 0, 
        "severity_value": 0.4711, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_weighted\n  Best score: 0.9422%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost f1_weighted", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: f1_weighted\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost f1_weighted", 
        "value": 0.9415, 
        "severity": 0, 
        "severity_value": 0.47075, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: f1_weighted\n  Best score: 0.9415%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels f1_macro", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: f1_macro\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels f1_macro", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: f1_macro\n  Best score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote f1_macro", 
        "value": 0.0296, 
        "severity": 0, 
        "severity_value": 0.0148, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: f1_macro\n  Best score: 0.0296%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels f1_macro", 
        "value": 0.0417, 
        "severity": 0, 
        "severity_value": 0.02085, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: f1_macro\n  Best score: 0.0417%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn f1_macro", 
        "value": 0.2054, 
        "severity": 0, 
        "severity_value": -0.2054, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: f1_macro\n  Worst score: 0.2054%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score knn f1_macro", 
        "value": 0.9684, 
        "severity": 0, 
        "severity_value": 0.4842, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: f1_macro\n  Best score: 0.9684%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression f1_macro", 
        "value": 0.1843, 
        "severity": 0, 
        "severity_value": -0.1843, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: f1_macro\n  Worst score: 0.1843%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression f1_macro", 
        "value": 0.9684, 
        "severity": 0, 
        "severity_value": 0.4842, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: f1_macro\n  Best score: 0.9684%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp f1_macro", 
        "value": 0.1429, 
        "severity": 0, 
        "severity_value": -0.1429, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: f1_macro\n  Worst score: 0.1429%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp f1_macro", 
        "value": 0.9955, 
        "severity": 0, 
        "severity_value": 0.49775, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: f1_macro\n  Best score: 0.9955%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches f1_macro", 
        "value": 0.7132, 
        "severity": 0, 
        "severity_value": 0.3566, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_macro\n  Best score: 0.7132%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost f1_macro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: f1_macro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost f1_macro", 
        "value": 0.8722, 
        "severity": 0, 
        "severity_value": 0.4361, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: f1_macro\n  Best score: 0.8722%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score true_labels f1_micro", 
        "value": 1, 
        "severity": 0, 
        "severity_value": -1.0, 
        "code": "worst_score >= -1", 
        "message": "Method true_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: f1_micro\n  Worst score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score true_labels f1_micro", 
        "value": 1, 
        "severity": 0, 
        "severity_value": 0.5, 
        "code": "best_score <= 2", 
        "message": "Method true_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: true_labels\n  Metric id: f1_micro\n  Best score: 1%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score majority_vote f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method majority_vote performs much worse than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score majority_vote f1_micro", 
        "value": 0.7133, 
        "severity": 0, 
        "severity_value": 0.35665, 
        "code": "best_score <= 2", 
        "message": "Method majority_vote performs a lot better than baselines.\n  Task id: label_projection\n  Method id: majority_vote\n  Metric id: f1_micro\n  Best score: 0.7133%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score random_labels f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method random_labels performs much worse than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score random_labels f1_micro", 
        "value": 0.058, 
        "severity": 0, 
        "severity_value": 0.029, 
        "code": "best_score <= 2", 
        "message": "Method random_labels performs a lot better than baselines.\n  Task id: label_projection\n  Method id: random_labels\n  Metric id: f1_micro\n  Best score: 0.058%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score knn f1_micro", 
        "value": 0.2192, 
        "severity": 0, 
        "severity_value": -0.2192, 
        "code": "worst_score >= -1", 
        "message": "Method knn performs much worse than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: f1_micro\n  Worst score: 0.2192%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score knn f1_micro", 
        "value": 0.9936, 
        "severity": 0, 
        "severity_value": 0.4968, 
        "code": "best_score <= 2", 
        "message": "Method knn performs a lot better than baselines.\n  Task id: label_projection\n  Method id: knn\n  Metric id: f1_micro\n  Best score: 0.9936%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score logistic_regression f1_micro", 
        "value": 0.1012, 
        "severity": 0, 
        "severity_value": -0.1012, 
        "code": "worst_score >= -1", 
        "message": "Method logistic_regression performs much worse than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: f1_micro\n  Worst score: 0.1012%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score logistic_regression f1_micro", 
        "value": 0.9936, 
        "severity": 0, 
        "severity_value": 0.4968, 
        "code": "best_score <= 2", 
        "message": "Method logistic_regression performs a lot better than baselines.\n  Task id: label_projection\n  Method id: logistic_regression\n  Metric id: f1_micro\n  Best score: 0.9936%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score mlp f1_micro", 
        "value": 0.2012, 
        "severity": 0, 
        "severity_value": -0.2012, 
        "code": "worst_score >= -1", 
        "message": "Method mlp performs much worse than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: f1_micro\n  Worst score: 0.2012%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score mlp f1_micro", 
        "value": 0.9957, 
        "severity": 0, 
        "severity_value": 0.49785, 
        "code": "best_score <= 2", 
        "message": "Method mlp performs a lot better than baselines.\n  Task id: label_projection\n  Method id: mlp\n  Metric id: f1_micro\n  Best score: 0.9957%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score scanvi_scarches f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method scanvi_scarches performs much worse than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score scanvi_scarches f1_micro", 
        "value": 0.9497, 
        "severity": 0, 
        "severity_value": 0.47485, 
        "code": "best_score <= 2", 
        "message": "Method scanvi_scarches performs a lot better than baselines.\n  Task id: label_projection\n  Method id: scanvi_scarches\n  Metric id: f1_micro\n  Best score: 0.9497%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Worst score xgboost f1_micro", 
        "value": 0.0, 
        "severity": 0, 
        "severity_value": -0.0, 
        "code": "worst_score >= -1", 
        "message": "Method xgboost performs much worse than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: f1_micro\n  Worst score: 0.0%\n"
    }, 
    {
        "task_id": "label_projection", 
        "category": "Scaling", 
        "name": "Best score xgboost f1_micro", 
        "value": 0.9438, 
        "severity": 0, 
        "severity_value": 0.4719, 
        "code": "best_score <= 2", 
        "message": "Method xgboost performs a lot better than baselines.\n  Task id: label_projection\n  Method id: xgboost\n  Metric id: f1_micro\n  Best score: 0.9438%\n"
    }
]