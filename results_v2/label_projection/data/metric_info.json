[
  {
    "id": "accuracy",
    "label": "Accuracy",
    "description": "The percentage of correctly predicted labels.",
    "min": 0,
    "max": 1,
    "maximize": true,
    "config_path": "metrics/accuracy/config.vsh.yaml",
    "component_id": "accuracy",
    "namespace": "label_projection/metrics",
    "component_description": "The percentage of correctly predicted labels.",
    "v1_url": "openproblems/tasks/label_projection/metrics/accuracy.py",
    "v1_commit": "fcd5b876e7d0667da73a2858bc27c40224e19f65"
  },
  {
    "id": "f1_weighted",
    "label": "F1 weighted",
    "description": "Calculates the F1 score for each label, and find their average weighted by support (the number of true instances for each label). This alters 'macro' to account for label imbalance; it can result in an F-score that is not between precision and recall.",
    "min": 0,
    "max": 1,
    "maximize": true,
    "config_path": "metrics/f1/config.vsh.yaml",
    "component_id": "f1",
    "namespace": "label_projection/metrics",
    "component_description": "balanced F-score or F-measure",
    "v1_url": "openproblems/tasks/label_projection/metrics/f1.py",
    "v1_commit": "bb16ca05ae1ce20ce59bfa7a879641b9300df6b0"
  },
  {
    "id": "f1_macro",
    "label": "F1 macro",
    "description": "Calculates the F1 score for each label, and find their unweighted mean. This does not take label imbalance into account.",
    "min": 0,
    "max": 1,
    "maximize": true,
    "config_path": "metrics/f1/config.vsh.yaml",
    "component_id": "f1",
    "namespace": "label_projection/metrics",
    "component_description": "balanced F-score or F-measure",
    "v1_url": "openproblems/tasks/label_projection/metrics/f1.py",
    "v1_commit": "bb16ca05ae1ce20ce59bfa7a879641b9300df6b0"
  },
  {
    "id": "f1_micro",
    "label": "F1 micro",
    "description": "Calculates the F1 score globally by counting the total true positives, false negatives and false positives.",
    "min": 0,
    "max": 1,
    "maximize": true,
    "config_path": "metrics/f1/config.vsh.yaml",
    "component_id": "f1",
    "namespace": "label_projection/metrics",
    "component_description": "balanced F-score or F-measure",
    "v1_url": "openproblems/tasks/label_projection/metrics/f1.py",
    "v1_commit": "bb16ca05ae1ce20ce59bfa7a879641b9300df6b0"
  }
]
